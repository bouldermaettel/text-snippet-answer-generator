# ----- LLM: Azure OpenAI or Ollama (local) -----
# Set LLM_PROVIDER to "azure", "ollama", or "auto" (default: auto = Azure if set, else Ollama).

# Azure OpenAI (use when deployed / cloud)
AZURE_OPENAI_ENDPOINT="https://smc-askyourdocs-openai.openai.azure.com/"
AZURE_OPENAI_API_KEY=
AZURE_OPENAI_CHAT_DEPLOYMENT="gpt-4-32k"
AZURE_OPENAI_EMBEDDING_DEPLOYMENT="text-embedding-3-small"
AZURE_OPENAI_API_VERSION="2024-12-01-preview"

# Ollama (use when running locally; no key required)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_CHAT_MODEL=llama3.2

# Optional: force provider (auto | azure | ollama | none)
# LLM_PROVIDER=auto
# HYDE_ENABLED=true  # allow hypothetical-answer retrieval when use_hyde is requested

# ----- Example Question Search (Hybrid Retrieval) -----
# Enable hybrid search that also matches user questions against example questions
# ENABLE_EXAMPLE_QUESTION_SEARCH=true
# EXAMPLE_QUESTION_SEARCH_WEIGHT=0.3  # weight for example question score in fusion (0.0-1.0)

# ----- Translation Indexing -----
# Enable cross-language retrieval by storing translated versions of snippets
# ENABLE_TRANSLATION_INDEXING=true
# TRANSLATION_LANGUAGES=en,de,fr,it  # comma-separated list of target languages

# ----- Embeddings (optional) -----
# EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
# USE_OPENAI_EMBEDDINGS=false
# OPENAI_API_KEY=

# ----- Data & chunking -----
# CHROMA_PERSIST_DIR=data/chroma
# CHUNK_SIZE=1500
# CHUNK_OVERLAP=200

# ----- Uploads -----
# UPLOAD_DIR=data/uploads  # default; set to empty to disable saving PDF/DOCX and document links

# ----- Auth (user management) -----
# JWT_SECRET=your-secret-key-min-32-chars  # required in production
# JWT_ALGORITHM=HS256
# JWT_EXPIRE_SECONDS=86400
# ADMIN_EMAIL=admin@example.com   # optional; seeds initial admin if no admin exists
# ADMIN_PASSWORD=your-admin-password
# DATABASE_URL=data/users.db
