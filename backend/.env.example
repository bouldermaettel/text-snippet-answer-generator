# ----- LLM: Azure OpenAI or Ollama (local) -----
# Set LLM_PROVIDER to "azure", "ollama", or "auto" (default: auto = Azure if set, else Ollama).

# Azure OpenAI (use when deployed / cloud)
AZURE_OPENAI_ENDPOINT="https://smc-askyourdocs-openai.openai.azure.com/"
AZURE_OPENAI_API_KEY=
AZURE_OPENAI_CHAT_DEPLOYMENT="gpt-4-32k"
AZURE_OPENAI_EMBEDDING_DEPLOYMENT="text-embedding-3-small"
AZURE_OPENAI_API_VERSION="2024-12-01-preview"

# Ollama (use when running locally; no key required)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_CHAT_MODEL=llama3.2

# Optional: force provider (auto | azure | ollama | none)
# LLM_PROVIDER=auto

# ----- Embeddings (optional) -----
# EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
# USE_OPENAI_EMBEDDINGS=false
# OPENAI_API_KEY=

# ----- Data -----
# CHROMA_PERSIST_DIR=data/chroma
